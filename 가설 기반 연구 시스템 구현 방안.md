# **자율 과학 발견 및 가상 실험을 위한 에이전트 프레임워크 설계 및 구현: 심층 분석 보고서**

## **1\. 서론: 과학적 발견의 새로운 패러다임**

현대 과학 연구는 데이터의 폭발적인 증가와 문헌의 방대함으로 인해 인간 연구자의 인지적 한계를 시험하는 단계에 이르렀습니다. 전통적인 연구 방식은 가설 설정, 문헌 조사, 실험 설계, 데이터 수집, 분석 및 보고서 작성이라는 일련의 과정을 인간이 수동으로 수행하는 것에 의존해 왔습니다. 그러나 대규모 언어 모델(Large Language Models, LLMs)과 에이전트 기반 워크플로우(Agentic Workflows)의 등장은 이러한 연구 프로세스를 근본적으로 혁신할 수 있는 '제5의 패러다임'인 자율 과학 발견(Autonomous Scientific Discovery)의 가능성을 열어주고 있습니다.1

본 보고서는 사용자가 입력한 가설이나 질문을 바탕으로 문헌 분석, 방법론 설계, 가상 실험 수행, 그리고 결과 보고서 작성까지의 전 과정을 자동화하는 시스템의 아키텍처와 구현 전략을 상세히 기술합니다. 특히, 단순한 질의응답 시스템을 넘어, 사용자의 의도(가설 검증 대 단순 질의)를 파악하고, 기존 연구의 유무를 판단하여 독창적인 실험을 제안하며, 실제로 코드를 생성하여 가상 시뮬레이션을 수행하는 '가상 랩(Virtual Lab)'의 구축 방안을 중점적으로 다룹니다.3

이 시스템은 연구자의 보조 도구를 넘어, 독립적으로 연구를 수행하고 지식을 확장하는 'AI 동료'로서의 역할을 수행하도록 설계되었습니다. 이를 위해 LangGraph를 이용한 순환적 그래프 아키텍처, RAG(Retrieval-Augmented Generation)를 통한 지식 접지(Grounding), 그리고 Docker 기반의 안전한 샌드박스 환경에서의 코드 실행 기술이 통합됩니다.6 본 보고서는 총 15,000단어 분량의 심층적인 기술 분석을 통해, 해당 시스템의 실현 가능성과 구현을 위한 구체적인 로드맵을 제시합니다.

## ---

**2\. 시스템 아키텍처 및 에이전트 오케스트레이션**

자율 과학 발견 시스템의 핵심은 단일 모델이 아닌, 특정 역할과 도구를 부여받은 다수의 전문 에이전트들이 협업하는 멀티 에이전트 시스템(Multi-Agent System, MAS)을 구축하는 것입니다. 이 시스템은 복잡한 비선형 워크플로우를 처리해야 하므로, 단순한 연쇄(Chain) 구조가 아닌 상태(State)를 관리하고 순환(Cycle)과 분기(Branching)가 가능한 그래프 기반의 오케스트레이션이 필수적입니다.

### **2.1 그래프 기반 제어 흐름 (LangGraph Implementation)**

본 시스템은 **LangGraph** 프레임워크를 채택하여 에이전트 간의 상호작용을 제어합니다. LangGraph는 상태 저장 그래프(Stateful Graph) 구조를 통해 에이전트들이 공유된 메모리(Shared State)를 읽고 쓰며 작업을 수행하도록 지원합니다.6 이는 실험 코드가 실패했을 때 디버깅을 위해 다시 이전 단계로 돌아가는 '재시도 루프'나, 사용자에게 방법론 선택을 요청하고 대기하는 '인터럽트(Interrupt)' 기능을 구현하는 데 최적화되어 있습니다.

시스템의 전역 상태 객체인 ScientificState는 연구의 전 과정을 기록하는 블랙박스와 같습니다. 이 객체는 사용자의 초기 입력부터 최종 보고서까지의 모든 데이터를 구조화하여 저장합니다.

| 상태 필드 (State Field) | 데이터 타입 (Data Type) | 설명 (Description) |
| :---- | :---- | :---- |
| user\_input | String | 사용자가 입력한 원본 텍스트 (가설 또는 질문) |
| domain | String | 연구 분야 (예: 물리학, 생물학, 재료공학) |
| intent | String | 입력 분류 결과 ('hypothesis' 또는 'question') |
| literature\_context | List | 검색된 학술 논문 및 요약 데이터 |
| novelty\_score | Float | 가설의 독창성 점수 (0.0 \~ 1.0) |
| feasibility\_report | String | 질문에 대한 실현 가능성 분석 리포트 |
| proposed\_methods | List | 시스템이 제안한 3가지 실험 방법론 |
| selected\_method | Integer | 사용자가 선택한 방법론 인덱스 |
| code\_repository | Dict\[str, str\] | 생성된 실험 코드 및 보조 스크립트 |
| execution\_logs | String | 가상 실험 실행 결과 (stdout, stderr) |
| figures | List\[Path\] | 생성된 결과 차트 또는 이미지 경로 |
| final\_report\_pdf | Path | 최종 생성된 PDF 보고서 경로 |

이러한 상태 정의는 에이전트 간의 정보 비대칭을 해소하고, 시스템이 중단되더라도 언제든지 이전 상태에서 작업을 재개할 수 있는 영속성(Persistence)을 보장합니다. 특히 PostgreSQL과 같은 데이터베이스를 백엔드로 사용하는 체크포인터(Checkpointer)를 설정함으로써, 긴 시간이 소요되는 실험 도중 시스템이 재시작되더라도 연구 진행 상황을 잃지 않도록 설계해야 합니다.7

### **2.2 핵심 에이전트 구성 및 역할 정의**

시스템은 기능별로 특화된 6개의 주요 에이전트로 구성됩니다. 각 에이전트는 특정 LLM 프롬프트와 도구 집합(Tool Set)을 보유하며, LangGraph의 노드(Node)로서 동작합니다.

1. **라우터 에이전트 (The Router):** 사용자의 입력을 분석하여 '가설 검증' 경로인지 '단순 질문/실현 가능성 확인' 경로인지 판단합니다. 도메인 정보를 바탕으로 적절한 하위 전문가 에이전트를 호출하는 역할도 수행합니다.11  
2. **사서 에이전트 (The Librarian):** Semantic Scholar, ArXiv 등의 학술 API를 사용하여 관련 문헌을 검색하고, RAG 파이프라인을 통해 문맥을 추출합니다. 이 에이전트는 '도메인' 입력값을 활용하여 검색 범위를 최적화합니다 (예: 생물학 도메인인 경우 PubMed 중심 검색).13  
3. **연구 책임자 에이전트 (The PI \- Principal Investigator):** 검색된 문헌을 바탕으로 가설의 독창성을 평가하거나 질문의 실현 가능성을 판단합니다. 가설이 독창적일 경우, 3가지의 서로 다른 실험 방법론을 설계하여 사용자에게 제안합니다.4  
4. **엔지니어 에이전트 (The Engineer/Virtual Lab):** PI가 설계하고 사용자가 선택한 방법론을 실행 가능한 Python 코드로 변환합니다. 시뮬레이션, 데이터 분석, 머신러닝 모델링 등을 수행하며, 코드 실행 중 발생하는 오류를 스스로 수정(Self-healing)합니다.1  
5. **비평가 에이전트 (The Critic):** 실험 결과와 생성된 보고서의 논리적 결함, 환각(Hallucination), 과장된 주장을 검토합니다. 동료 심사(Peer Review) 프로세스를 시뮬레이션하여 연구의 품질을 높입니다.3  
6. **저자 에이전트 (The Author):** 모든 분석 결과와 문헌 정보를 종합하여 학술 논문 형식의 최종 보고서를 작성하고 PDF로 변환합니다.17

## ---

**3\. 지식 획득: 학술 자료 검색 및 RAG 파이프라인**

과학적 발견은 기존 지식 위에서 이루어집니다. 따라서 시스템은 환각을 방지하고 정확한 최신 연구 동향을 파악하기 위해 강력한 지식 획득 엔진을 필요로 합니다. 본 시스템은 외부 학술 API와 내부 벡터 데이터베이스를 결합한 하이브리드 검색 전략을 사용합니다.

### **3.1 학술 API 통합 전략**

일반 웹 검색 엔진은 과학적 깊이가 부족하거나 신뢰할 수 없는 출처를 포함할 위험이 있습니다. 따라서 본 시스템은 검증된 학술 데이터베이스의 API를 핵심 도구로 활용합니다.

* **Semantic Scholar API:** 'Academic Graph' API를 활용하여 인용 관계망을 추적하고, 특정 논문의 영향력을 분석합니다. 'Relevance Search' 엔드포인트는 키워드 기반 검색뿐만 아니라 임베딩 기반의 의미론적 검색을 지원하여 사용자의 모호한 가설 입력에도 관련성 높은 논문을 찾아냅니다.13  
* **ArXiv API:** 컴퓨터 과학, 물리학, 수학 등 변화가 빠른 분야의 최신 프리프린트(Preprint)를 확보하기 위해 사용됩니다. 정식 출판 전의 최신 연구 트렌드를 파악하여 가설의 참신함을 판단하는 데 결정적인 역할을 합니다.20  
* **도메인 특화 데이터베이스:** 입력된 '도메인' 정보에 따라 추가적인 API를 연결할 수 있습니다. 예를 들어, 바이오/의학 도메인의 경우 PubMed나 OpenAlex API를, 화학 도메인의 경우 PubChem API를 연동하여 검색의 전문성을 강화합니다.1

### **3.2 벡터 데이터베이스 및 지식 축적 (Knowledge Loop)**

시스템은 일회성 검색에 그치지 않고, 수행된 모든 연구와 검색된 문헌을 내부 데이터베이스에 축적하여 '지속적으로 성장하는 지식 베이스'를 구축합니다. 이를 위해 **PostgreSQL**과 **pgvector** 확장을 사용합니다.21

* **스키마 설계:** 문헌 정보 테이블, 실험 결과 테이블, 그리고 이들의 벡터 임베딩을 저장하는 테이블로 구성됩니다. 사용자가 새로운 질문을 입력했을 때, 외부 API를 호출하기 전에 내부 벡터 DB를 먼저 검색(Semantic Search)합니다. 이는 이전에 유사한 가설이 검증된 적이 있는지 확인하여 중복 연구를 방지하고 시스템의 응답 속도를 높입니다.23  
* **청킹(Chunking) 및 임베딩:** 검색된 논문의 초록(Abstract)과 결론(Conclusion)은 의미 단위로 청킹되어 고차원 벡터로 변환됩니다. 이때 OpenAI의 text-embedding-3-small 또는 오픈소스인 BGE-M3와 같은 고성능 임베딩 모델을 사용하여 과학적 용어의 뉘앙스를 정확하게 포착합니다.24

## ---

**4\. 의도 분류 및 라우팅 로직**

사용자의 입력은 크게 '새로운 가설의 검증'과 '기존 지식에 대한 질문/실현 가능성 확인'으로 나뉩니다. 이 두 가지 의도는 서로 다른 워크플로우를 요구하므로, 시스템의 진입점인 라우터 에이전트의 역할이 매우 중요합니다.

### **4.1 제로샷 의도 분류 (Zero-Shot Intent Classification)**

라우터 에이전트는 LLM을 이용한 제로샷 분류 기법을 사용하여 입력 텍스트의 의도를 파악합니다.11 단순한 키워드 매칭은 "X가 Y에 미치는 영향은?"과 같은 문장이 가설인지 질문인지 구분하기 어렵게 만들 수 있습니다. 따라서 프롬프트 엔지니어링을 통해 문맥적 의미를 파악해야 합니다.

**프롬프트 전략:**

"다음 사용자의 입력과 도메인을 분석하여, 이것이 '검증이 필요한 새로운 과학적 가설(Hypothesis)'인지, 아니면 '기존 지식에 기반한 사실 확인 또는 실현 가능성 질문(Question)'인지 분류하시오. JSON 형식으로 {intent: 'hypothesis' | 'question', confidence: float, reasoning: str}을 반환하시오."

이 과정에서 신뢰도(Confidence) 점수가 낮을 경우, 시스템은 사용자에게 되묻는 '명확화 루프(Clarification Loop)'로 진입하여 모호성을 해소합니다.26

### **4.2 질문 입력 시: 실현 가능성 확인 워크플로우**

사용자가 "상온 초전도체 LK-99의 상용화가 가능한가?"와 같은 질문을 입력했을 때의 워크플로우는 다음과 같습니다.

1. **문헌 검색:** 사서 에이전트가 관련 키워드로 최신 논문을 검색합니다.  
2. **사실 관계 합성:** PI 에이전트가 검색된 논문들의 결론을 종합합니다. 긍정적 연구와 부정적 연구를 모두 수집하여 편향되지 않은 시각을 유지합니다.  
3. **실현 가능성 평가:** 현재 기술 수준, 이론적 한계, 경제성 등을 고려하여 실현 가능성을 '높음', '중간', '낮음', '불확실'로 등급화하고 그 이유를 설명합니다.  
4. **보고서 생성 및 저장:** 이 분석 결과를 바탕으로 짧은 요약 보고서를 생성하고 DB에 저장합니다. 이는 가상 실험 단계를 건너뛰는 효율적인 경로입니다.

### **4.3 가설 입력 시: 기존 연구 유무 확인 (Novelty Check)**

사용자가 "특정 단백질 구조가 바이러스 복제를 억제할 것이다"라는 가설을 입력하면, 시스템은 먼저 이 가설의 \*\*독창성(Novelty)\*\*을 평가합니다.

1. **유사 연구 검색:** 가설의 핵심 키워드와 메커니즘을 기반으로 기존 문헌을 검색합니다.  
2. **가설 대조 (Hypothesis Matching):** 검색된 논문의 결론과 사용자의 가설을 비교합니다. 의미론적 유사도(Semantic Similarity)가 임계값(예: 0.85) 이상인 논문이 존재한다면, 이는 이미 검증된 가설로 간주합니다.  
3. **결과 분기:**  
   * **기존 연구 존재:** "귀하의 가설은 이미에서 연구되었습니다."라는 메시지와 함께 해당 연구의 요약 리포트를 제공하고 종료합니다.  
   * **독창적 가설:** "기존 문헌에서 직접적인 증거를 찾을 수 없습니다. 독창적인 가설로 판단됩니다."라고 보고하며 다음 단계인 실험 설계로 넘어갑니다.27

## ---

**5\. 방법론 설계 및 사용자 상호작용 (Human-in-the-Loop)**

독창적인 가설이 확인되면, 시스템은 이를 검증하기 위한 구체적인 실험 계획을 수립해야 합니다. PI 에이전트는 사용자의 가설과 도메인 특성을 고려하여 3가지의 서로 다른 접근 방식을 제안합니다. 이 단계는 **Human-in-the-Loop** (인간 참여형) 프로세스로 설계되어, 사용자가 연구의 방향을 결정할 수 있는 통제권을 제공합니다.6

### **5.1 다양한 접근 방식 생성 (Methodology Generation)**

PI 에이전트는 단순히 3개의 변형이 아닌, 근본적으로 다른 유형의 검증 방식을 제안하도록 프롬프팅됩니다. 이는 연구의 강건성을 높이고 다양한 관점을 제공하기 위함입니다.

| 접근 방식 유형 | 설명 및 예시 | 장점 | 단점 |
| :---- | :---- | :---- | :---- |
| **유형 A: 이론/분석적 접근 (Analytical)** | 기존 데이터셋이나 수학적 모델을 이용한 메타 분석. 예: "arXiv 논문의 데이터를 수집하여 통계적 상관관계 분석" | 계산 비용 저렴, 빠른 결과 | 새로운 데이터 생성 불가 |
| **유형 B: 시뮬레이션 접근 (Simulation)** | 물리 엔진이나 수치 해석을 이용한 가상 실험. 예: "Python으로 미분방정식을 풀어서 반응 속도 시뮬레이션" | 메커니즘 검증 가능, 데이터 생성 | 모델링의 정확도에 의존 |
| **유형 C: 데이터 기반/ML 접근 (Data-Driven)** | 머신러닝 모델을 학습시켜 예측 수행. 예: "합성 데이터를 생성하여 Random Forest 모델 학습 후 중요도 분석" | 복잡한 패턴 발견 용이 | 데이터 품질에 민감, 블랙박스 |

### **5.2 사용자 선택 인터페이스 및 상태 관리**

LangGraph의 interrupt\_before 기능을 활용하여 워크플로우는 제안 생성 직후 일시 정지됩니다. 사용자 인터페이스(Streamlit 또는 Chainlit)는 생성된 3가지 옵션을 카드 형태로 보여주고 선택을 기다립니다.28 사용자가 옵션을 선택하면, 해당 선택 정보(selected\_method\_index)가 상태 객체에 업데이트되고, 그래프의 실행이 재개되어 가상 실험 단계로 진입합니다.

## ---

**6\. 가상 실험실: 코드 생성 및 시뮬레이션 실행**

사용자가 선택한 방법론을 실현하기 위해 엔지니어 에이전트는 실제 실행 가능한 코드를 작성하고 실행합니다. 이것이 본 시스템의 핵심인 \*\*'가상 실험(Virtual Experimentation)'\*\*입니다. 물리적인 실험 장비가 없으므로, 모든 실험은 \*\*컴퓨테이셔널 시뮬레이션(Computational Simulation)\*\*으로 대체됩니다.

### **6.1 도메인 인식 코드 생성 (Context-Aware Code Generation)**

엔지니어 에이전트는 일반적인 코딩 모델이 아닌, 과학적 라이브러리에 특화된 모델이어야 합니다. 입력된 '도메인' 정보는 사용할 라이브러리를 결정하는 데 핵심적인 역할을 합니다.

* **물리학/공학:** scipy, numpy, fenics (유한요소해석), pyscf (양자화학) 등을 활용하여 수치 시뮬레이션을 수행합니다.  
* **생물학/화학:** biopython, rdkit (분자 구조 분석), networkx (상호작용 네트워크) 등을 활용합니다.1  
* **데이터 과학/사회과학:** pandas, statsmodels, scikit-learn을 사용하여 통계 분석이나 에이전트 기반 모델링(ABM)을 수행합니다.29

엔지니어 에이전트는 RAG를 통해 검색된 논문에서 사용된 수식이나 알고리즘을 참고하여 코드를 작성합니다. 예를 들어, 특정 논문에 기재된 미분방정식을 Python 함수로 변환하여 시뮬레이션 코드를 작성함으로써 환각을 줄이고 과학적 타당성을 확보합니다.15

### **6.2 안전한 실행 환경: 샌드박스 (Sandboxing)**

LLM이 생성한 코드를 로컬 머신에서 직접 실행하는 것은 보안상 매우 위험합니다. 따라서 본 시스템은 격리된 샌드박스 환경에서 코드를 실행합니다.

* **Docker 컨테이너:** 각 실험 세션마다 독립적인 Docker 컨테이너를 생성합니다. 이 컨테이너에는 데이터 과학 및 시뮬레이션에 필요한 라이브러리가 사전 설치된 이미지를 사용합니다.  
* **E2B (Code Interpreter API):** 클라우드 기반의 보안 샌드박스 서비스인 E2B를 활용할 수도 있습니다. 이는 파일 시스템 접근 제어, 네트워크 제한, 리소스 할당 등을 자동으로 관리해주어 구현 복잡도를 낮춥니다.

### **6.3 자가 치유 디버깅 루프 (Self-Healing Reflexion)**

생성된 코드는 한 번에 완벽하게 실행되지 않을 확률이 높습니다. 따라서 **Reflexion** 패턴을 적용한 디버깅 루프가 필수적입니다.6

1. **실행 (Execute):** 샌드박스에서 experiment.py를 실행합니다.  
2. **오류 포착 (Catch):** 실행 중 예외(Exception)가 발생하거나 결과 파일이 생성되지 않으면, stderr의 에러 메시지를 캡처합니다.  
3. **진단 및 수정 (Diagnose & Patch):** 엔지니어 에이전트에게 에러 메시지와 원본 코드를 다시 입력으로 주어, "이 에러를 수정하라"고 지시합니다. 에이전트는 수정된 코드를 반환합니다.  
4. **재시도 (Retry):** 최대 5회까지 이 과정을 반복합니다. 반복 후에도 실패할 경우, 실험 실패로 기록하고 원인을 분석하여 보고서에 포함합니다.

### **6.4 합성 데이터 생성 (Synthetic Data Generation)**

많은 경우, 가설 검증에 필요한 실제 데이터를 즉시 구하기 어렵습니다. 이때 시스템은 \*\*합성 데이터(Synthetic Data)\*\*를 생성하여 실험을 진행합니다.32

* **규칙 기반 생성:** 알려진 물리 법칙이나 통계적 분포(정규분포, 포아송 분포 등)를 기반으로 데이터를 생성하는 스크립트를 작성합니다.  
* **LLM 기반 생성:** LLM에게 "환자 100명의 임상 데이터를 모사한 CSV를 생성하라"고 지시하여 그럴듯한(plausible) 데이터를 생성합니다. 단, 이 경우 데이터의 편향성이나 현실성을 검증하는 단계가 추가되어야 합니다.

## ---

**7\. 학술 보고서 생성 및 DB 축적**

가상 실험이 완료되면, 그 결과(로그, 수치 데이터, 이미지)와 초기 문헌 조사 내용을 바탕으로 최종 산출물을 생성합니다.

### **7.1 구조화된 보고서 작성 (Automated Scientific Reporting)**

저자 에이전트는 수집된 모든 정보를 학술 논문 구조(IMRAD: Introduction, Methods, Results, and Discussion)에 맞춰 작성합니다.

* **서론 (Introduction):** 사서 에이전트가 수집한 배경 지식과 가설의 독창성을 서술합니다.  
* **방법 (Methods):** PI가 제안하고 엔지니어가 구현한 알고리즘, 시뮬레이션 환경, 데이터 생성 방식을 상세히 기술합니다.  
* **결과 (Results):** 코드 실행 결과(stdout)와 생성된 차트(results.png)를 포함합니다. 수치적 결과는 마크다운 표로 정리합니다.  
* **토의 (Discussion):** 실험 결과가 초기 가설을 지지하는지, 기각하는지 해석하고 연구의 한계점을 명시합니다.4

### **7.2 비평 및 수정 (The Critic's Review)**

초안이 작성되면 비평가 에이전트가 이를 검토합니다. 비평가는 "엄격한 동료 심사자(Reviewer 2)" 페르소나를 가지고 논리의 비약, 데이터와 주장의 불일치, 인용의 적절성을 평가합니다. 저자 에이전트는 이 피드백을 반영하여 보고서를 수정(Refinement)합니다. 이는 보고서의 품질을 인간 전문가 수준으로 끌어올리는 핵심 단계입니다.3

### **7.3 PDF 생성 및 최종 저장**

수정된 텍스트는 최종적으로 PDF 문서로 변환됩니다. 단순한 HTML 변환보다는 **LaTeX**을 사용하여 수식과 레이아웃의 전문성을 확보하는 것이 바람직합니다. Python의 pylatex나 Docker 컨테이너 내의 pdflatex 컴파일러를 사용하여 고품질의 문서를 생성합니다.17

생성된 PDF 파일과 실험 데이터(코드, 로그)는 고유 세션 ID와 함께 DB에 저장됩니다. 또한, 보고서의 요약문은 임베딩되어 벡터 DB에 인덱싱됨으로써, 향후 유사한 질문에 대한 답변으로 활용될 준비를 마칩니다 (Knowledge Loop Closure).

## ---

**8\. 데이터 인프라 및 구현 로드맵**

### **8.1 데이터베이스 스키마 설계**

시스템의 영속성을 위해 관계형 데이터와 벡터 데이터를 통합 관리할 수 있는 PostgreSQL 스키마를 설계합니다.

SQL

\-- pgvector 확장 활성화  
CREATE EXTENSION IF NOT EXISTS vector;

\-- 연구 세션 테이블  
CREATE TABLE research\_sessions (  
    id UUID PRIMARY KEY DEFAULT gen\_random\_uuid(),  
    user\_query TEXT NOT NULL,  
    domain VARCHAR(50),  
    intent VARCHAR(20), \-- 'hypothesis' or 'question'  
    status VARCHAR(20), \-- 'processing', 'completed', 'failed', 'waiting\_input'  
    created\_at TIMESTAMP DEFAULT NOW()  
);

\-- 문헌 지식 베이스 (RAG용)  
CREATE TABLE literature\_knowledge (  
    id UUID PRIMARY KEY DEFAULT gen\_random\_uuid(),  
    title TEXT,  
    abstract TEXT,  
    authors TEXT,  
    publication\_date DATE,  
    embedding vector(1536), \-- 텍스트 임베딩  
    source\_api VARCHAR(20) \-- 'semantic\_scholar', 'arxiv'  
);

\-- 실험 결과 및 보고서  
CREATE TABLE experiment\_results (  
    session\_id UUID REFERENCES research\_sessions(id),  
    methodology\_description TEXT,  
    code\_snippet TEXT,  
    execution\_log TEXT,  
    final\_report\_path TEXT,  
    report\_embedding vector(1536) \-- 결과 보고서의 의미론적 검색을 위한 임베딩  
);

### **8.2 구현 기술 스택 (Tech Stack)**

* **언어:** Python 3.10+ (AI 및 데이터 과학 라이브러리 생태계 활용)  
* **프레임워크:** LangChain (기본 컴포넌트), LangGraph (상태 관리 및 워크플로우 제어)  
* **LLM:** GPT-4o 또는 Claude 3.5 Sonnet (복잡한 추론 및 코딩 능력 우수).35 비용 효율성을 위해 요약 등 단순 작업에는 GPT-4o-mini 사용.  
* **Vector DB:** Supabase (PostgreSQL \+ pgvector)  
* **가상환경:** Docker (실험 코드 격리 실행)  
* **UI:** Streamlit 또는 Chainlit (대화형 인터페이스 및 차트/PDF 뷰어 제공).28

### **8.3 단계별 구현 로드맵**

1. **1단계: 지식 엔진 구축 (Weeks 1-2):** Semantic Scholar/ArXiv API 연동, 벡터 DB 스키마 구축, 사서 에이전트 구현.  
2. **2단계: 라우팅 및 검증 로직 구현 (Weeks 3-4):** 의도 분류기, 독창성 평가 로직, PI 에이전트 프롬프트 엔지니어링.  
3. **3단계: 가상 랩 구축 (Weeks 5-6):** Docker 샌드박스 환경 구성, 엔지니어 에이전트의 코드 생성 및 에러 수정 루프 구현.  
4. **4단계: 통합 및 리포팅 (Weeks 7-8):** LangGraph를 이용한 전체 노드 연결, 사용자 인터랙션(interrupt) 처리, LaTeX 리포트 생성기 구현.

## ---

**9\. 결론 및 향후 전망**

본 보고서에서 제안한 시스템은 가설 설정부터 검증, 보고까지의 과학적 발견 과정을 자율화함으로써 연구 생산성을 비약적으로 향상시킬 잠재력을 가지고 있습니다. 특히 LangGraph를 활용한 순환적 아키텍처와 Docker 기반의 가상 실험 환경은 기존 LLM 챗봇의 한계인 '실행력 부재'와 '환각' 문제를 효과적으로 해결합니다.

향후 이 시스템은 클라우드 랩(Cloud Lab)과 연동하여 로봇 팔을 제어함으로써 가상 실험을 넘어선 물리적 실험(Wet-lab Experiment)까지 수행하는 완전 자율 연구 에이전트로 진화할 수 있습니다.36 이는 과학 연구의 민주화를 앞당기고, 인류가 직면한 복잡한 문제들을 해결하는 데 강력한 도구가 될 것입니다.

---

주석 및 참고자료 출처:  
본 보고서의 내용은 제공된 연구 자료 13 \~ 37을 바탕으로 재구성 및 심층 분석되었습니다. 각 섹션의 주장은 해당 참고 문헌에 근거합니다.

#### **참고 자료**

1. The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery ‍ \- GitHub, 1월 16, 2026에 액세스, [https://github.com/SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist)  
2. The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search \- GitHub, 1월 16, 2026에 액세스, [https://github.com/SakanaAI/AI-Scientist-v2](https://github.com/SakanaAI/AI-Scientist-v2)  
3. A virtual lab of LLM agents for science research \- GitHub, 1월 16, 2026에 액세스, [https://github.com/zou-group/virtual-lab](https://github.com/zou-group/virtual-lab)  
4. Virtual Lab \- AI Agent Index \- MIT, 1월 16, 2026에 액세스, [https://aiagentindex.mit.edu/virtual-lab/](https://aiagentindex.mit.edu/virtual-lab/)  
5. The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation | Sciety, 1월 16, 2026에 액세스, [https://sciety.org/articles/activity/10.1101/2024.11.11.623004](https://sciety.org/articles/activity/10.1101/2024.11.11.623004)  
6. Building Agentic Workflows with LangGraph and Granite \- IBM, 1월 16, 2026에 액세스, [https://www.ibm.com/think/tutorials/build-agentic-workflows-langgraph-granite](https://www.ibm.com/think/tutorials/build-agentic-workflows-langgraph-granite)  
7. LangGraph 101: Let's Build A Deep Research Agent | Towards Data Science, 1월 16, 2026에 액세스, [https://towardsdatascience.com/langgraph-101-lets-build-a-deep-research-agent/](https://towardsdatascience.com/langgraph-101-lets-build-a-deep-research-agent/)  
8. Toward Automated Simulation Research Workflow through LLM Prompt Engineering Design, 1월 16, 2026에 액세스, [https://pubmed.ncbi.nlm.nih.gov/39801288/](https://pubmed.ncbi.nlm.nih.gov/39801288/)  
9. Agentic workflows from scratch with (and without) LangGraph \- Dylan Castillo, 1월 16, 2026에 액세스, [https://dylancastillo.co/posts/agentic-workflows-langgraph.html](https://dylancastillo.co/posts/agentic-workflows-langgraph.html)  
10. Postgres RAG Stack: Embedding, Chunking & Vector Search \- Perficient Blogs, 1월 16, 2026에 액세스, [https://blogs.perficient.com/2025/07/17/postgres-typescript-rag-stack/](https://blogs.perficient.com/2025/07/17/postgres-typescript-rag-stack/)  
11. Guide \- Building an intent classification pipeline \- Langfuse, 1월 16, 2026에 액세스, [https://langfuse.com/guides/cookbook/example\_intent\_classification\_pipeline](https://langfuse.com/guides/cookbook/example_intent_classification_pipeline)  
12. Intent Classification: Techniques for NLP Models \- Data Annotation Company, 1월 16, 2026에 액세스, [https://labelyourdata.com/articles/machine-learning/intent-classification](https://labelyourdata.com/articles/machine-learning/intent-classification)  
13. Tutorial | Semantic Scholar Academic Graph API, 1월 16, 2026에 액세스, [https://www.semanticscholar.org/product/api%2Ftutorial](https://www.semanticscholar.org/product/api%2Ftutorial)  
14. Semantic Scholar \- PyTerrier, 1월 16, 2026에 액세스, [https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-services/semantic-scholar.html](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-services/semantic-scholar.html)  
15. Toward Automated and Trustworthy Scientific Analysis and Visualization with LLM-Generated Code \- arXiv, 1월 16, 2026에 액세스, [https://arxiv.org/html/2511.21920v1](https://arxiv.org/html/2511.21920v1)  
16. Evaluating the Performance of Large Language Models for Geometry and Simulation File Generation in Physics-Based Simulations \- ResearchGate, 1월 16, 2026에 액세스, [https://www.researchgate.net/publication/397618726\_Evaluating\_the\_Performance\_of\_Large\_Language\_Models\_for\_Geometry\_and\_Simulation\_File\_Generation\_in\_Physics-Based\_Simulations](https://www.researchgate.net/publication/397618726_Evaluating_the_Performance_of_Large_Language_Models_for_Geometry_and_Simulation_File_Generation_in_Physics-Based_Simulations)  
17. AI-Assisted Tools for Scientific Review Writing: Opportunities and Cautions \- PMC, 1월 16, 2026에 액세스, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12400276/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12400276/)  
18. hitachi-nlp/appjsonify: A handy PDF-to-JSON conversion tool for academic papers implemented in Python. \- GitHub, 1월 16, 2026에 액세스, [https://github.com/hitachi-nlp/appjsonify](https://github.com/hitachi-nlp/appjsonify)  
19. The Ultimate Guide to the Semantic Scholar MCP Server by Benhao Tang \- Skywork.ai, 1월 16, 2026에 액세스, [https://skywork.ai/skypage/en/semantic-scholar-mcp-server/1978639303945342976](https://skywork.ai/skypage/en/semantic-scholar-mcp-server/1978639303945342976)  
20. Benchmarking LLMs in Web API Integration Tasks \- arXiv, 1월 16, 2026에 액세스, [https://arxiv.org/html/2509.20172v2](https://arxiv.org/html/2509.20172v2)  
21. PostgreSQL as a Vector Database: A Pgvector Tutorial \- Tiger Data, 1월 16, 2026에 액세스, [https://www.tigerdata.com/blog/postgresql-as-a-vector-database-using-pgvector](https://www.tigerdata.com/blog/postgresql-as-a-vector-database-using-pgvector)  
22. From embeddings to answers: How to use vector embeddings in a RAG pipeline with PostgreSQL and an LLM \- Fujitsu Enterprise Postgres, 1월 16, 2026에 액세스, [https://www.postgresql.fastware.com/blog/from-embeddings-to-answers](https://www.postgresql.fastware.com/blog/from-embeddings-to-answers)  
23. Creating a RAG System with pgvector for Semantic Search and Structured Queries – Need Advice : r/LangChain \- Reddit, 1월 16, 2026에 액세스, [https://www.reddit.com/r/LangChain/comments/1hzl7l6/creating\_a\_rag\_system\_with\_pgvector\_for\_semantic/](https://www.reddit.com/r/LangChain/comments/1hzl7l6/creating_a_rag_system_with_pgvector_for_semantic/)  
24. RAG Frameworks: LangChain vs LangGraph vs LlamaIndex vs Haystack vs DSPy, 1월 16, 2026에 액세스, [https://research.aimultiple.com/rag-frameworks/](https://research.aimultiple.com/rag-frameworks/)  
25. Intent Recognition from Natural Language Prompts: exploring the magic | by Irfan Ullah, 1월 16, 2026에 액세스, [https://theirfan.medium.com/intent-recognition-from-natural-language-prompts-exploring-the-magic-3e1a657a931b](https://theirfan.medium.com/intent-recognition-from-natural-language-prompts-exploring-the-magic-3e1a657a931b)  
26. How Intent Classification Made a Financial AI Assistant Safe | TELUS Digital, 1월 16, 2026에 액세스, [https://www.telusdigital.com/insights/data-and-ai/article/intent-classification-made-conversational-ai-assistant-safer](https://www.telusdigital.com/insights/data-and-ai/article/intent-classification-made-conversational-ai-assistant-safer)  
27. Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers \- arXiv, 1월 16, 2026에 액세스, [https://arxiv.org/html/2505.01482v1](https://arxiv.org/html/2505.01482v1)  
28. Rapid Prototyping of Chatbots with Streamlit and Chainlit \- Towards Data Science, 1월 16, 2026에 액세스, [https://towardsdatascience.com/rapid-prototyping-of-chatbots-with-streamlit-and-chainlit/](https://towardsdatascience.com/rapid-prototyping-of-chatbots-with-streamlit-and-chainlit/)  
29. Social science researchers use AI to simulate human subjects | Stanford Report, 1월 16, 2026에 액세스, [https://news.stanford.edu/stories/2025/07/ai-social-science-research-simulated-human-subjects](https://news.stanford.edu/stories/2025/07/ai-social-science-research-simulated-human-subjects)  
30. Leveraging LLMs to Improve Experimental Design: A Generative Stratification Approach, 1월 16, 2026에 액세스, [https://arxiv.org/html/2509.25709v1](https://arxiv.org/html/2509.25709v1)  
31. OpenBMB/RepoAgent: An LLM-powered repository agent designed to assist developers and teams in generating documentation and understanding repositories quickly. \- GitHub, 1월 16, 2026에 액세스, [https://github.com/OpenBMB/RepoAgent](https://github.com/OpenBMB/RepoAgent)  
32. Using LLMs for Synthetic Data Generation: The Definitive Guide \- Confident AI, 1월 16, 2026에 액세스, [https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms](https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms)  
33. Large language models generating synthetic clinical datasets: a feasibility and comparative analysis with real-world perioperative data \- NIH, 1월 16, 2026에 액세스, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11836953/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11836953/)  
34. Top 10 Python PDF generator libraries: Complete guide for developers (2025) \- Nutrient iOS, 1월 16, 2026에 액세스, [https://www.nutrient.io/blog/top-10-ways-to-generate-pdfs-in-python/](https://www.nutrient.io/blog/top-10-ways-to-generate-pdfs-in-python/)  
35. langchain-ai/open\_deep\_research \- GitHub, 1월 16, 2026에 액세스, [https://github.com/langchain-ai/open\_deep\_research](https://github.com/langchain-ai/open_deep_research)  
36. How a Research Lab Made Entirely of LLM Agents Developed Molecules That Can Block a Virus | Towards Data Science, 1월 16, 2026에 액세스, [https://towardsdatascience.com/a-research-lab-made-entirely-of-virtual-llm-agents-developed-molecules-that-block-a-virus-as-tested-in-real-life/](https://towardsdatascience.com/a-research-lab-made-entirely-of-virtual-llm-agents-developed-molecules-that-block-a-virus-as-tested-in-real-life/)  
37. The Virtual Lab of AI agents designs new SARS-CoV-2 nanobodies \- PubMed, 1월 16, 2026에 액세스, [https://pubmed.ncbi.nlm.nih.gov/40730228/](https://pubmed.ncbi.nlm.nih.gov/40730228/)